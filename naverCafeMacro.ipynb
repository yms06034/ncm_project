{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e66ecd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (4.5.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (2.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.0.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: BeautifulSoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from BeautifulSoup4) (2.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (2.18.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from requests) (2.6)\n",
      "Collecting urllib3<1.23,>=1.21.1\n",
      "  Using cached urllib3-1.22-py2.py3-none-any.whl (132 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\n",
      "selenium 4.5.0 requires urllib3[socks]~=1.26, but you have urllib3 1.22 which is incompatible.\n",
      "google-cloud-core 1.7.1 requires google-api-core<2.0.0dev,>=1.21.0, but you have google-api-core 2.11.0 which is incompatible.\n",
      "google-cloud-core 1.7.1 requires google-auth<2.0dev,>=1.24.0, but you have google-auth 2.16.0 which is incompatible.\n",
      "cookiecutter 1.7.3 requires requests>=2.23.0, but you have requests 2.18.4 which is incompatible.\n",
      "conda 22.9.0 requires requests>=2.20.1, but you have requests 2.18.4 which is incompatible.\n",
      "botocore 1.24.32 requires urllib3<1.27,>=1.25.4, but you have urllib3 1.22 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.14\n",
      "    Uninstalling urllib3-1.26.14:\n",
      "      Successfully uninstalled urllib3-1.26.14\n",
      "Successfully installed urllib3-1.22\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.21.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting webdriver_manager\n",
      "  Using cached webdriver_manager-3.8.6-py2.py3-none-any.whl (27 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver_manager) (21.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver_manager) (4.64.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from webdriver_manager) (2.18.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->webdriver_manager) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from requests->webdriver_manager) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2021.10.8)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from requests->webdriver_manager) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (from requests->webdriver_manager) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->webdriver_manager) (0.4.4)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.0 webdriver-manager-3.8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dotenv.exe is installed in 'C:\\Users\\yms06\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyperclip in c:\\users\\yms06\\appdata\\roaming\\python\\python39\\site-packages (1.8.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fake-useragent\n",
      "  Downloading fake_useragent-1.1.3-py3-none-any.whl (50 kB)\n",
      "Collecting importlib-resources>=5.0\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-resources>=5.0->fake-useragent) (3.7.0)\n",
      "Installing collected packages: importlib-resources, fake-useragent\n",
      "Successfully installed fake-useragent-1.1.3 importlib-resources-5.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install BeautifulSoup4\n",
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install webdriver_manager\n",
    "!pip install pyperclip\n",
    "!pip install fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c0dfe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import pyperclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99bc251a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"app\"]/div/div/div[2]/div[2]/div[5]/div[2]/div[1]/textarea\"}\n  (Session info: chrome=114.0.5735.134); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x0031A813+48355]\n\t(No symbol) [0x002AC4B1]\n\t(No symbol) [0x001B5358]\n\t(No symbol) [0x001E09A5]\n\t(No symbol) [0x001E0B3B]\n\t(No symbol) [0x0020E232]\n\t(No symbol) [0x001FA784]\n\t(No symbol) [0x0020C922]\n\t(No symbol) [0x001FA536]\n\t(No symbol) [0x001D82DC]\n\t(No symbol) [0x001D93DD]\n\tGetHandleVerifier [0x0057AABD+2539405]\n\tGetHandleVerifier [0x005BA78F+2800735]\n\tGetHandleVerifier [0x005B456C+2775612]\n\tGetHandleVerifier [0x003A51E0+616112]\n\t(No symbol) [0x002B5F8C]\n\t(No symbol) [0x002B2328]\n\t(No symbol) [0x002B240B]\n\t(No symbol) [0x002A4FF7]\n\tBaseThreadInitThunk [0x764C7D59+25]\n\tRtlInitializeExceptionChain [0x778DB74B+107]\n\tRtlClearBits [0x778DB6CF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m     browser\u001b[38;5;241m.\u001b[39mget(r_href)\n\u001b[0;32m    110\u001b[0m     browser\u001b[38;5;241m.\u001b[39mswitch_to\u001b[38;5;241m.\u001b[39mframe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcafe_main\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m     text_area \u001b[38;5;241m=\u001b[39m \u001b[43mfind_xpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//*[@id=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]/div/div/div[2]/div[2]/div[5]/div[2]/div[1]/textarea\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     text_area\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m    115\u001b[0m pyperclip\u001b[38;5;241m.\u001b[39mcopy(COMMENTS) \n",
      "Cell \u001b[1;32mIn[92], line 14\u001b[0m, in \u001b[0;36mfind_xpath\u001b[1;34m(xpath)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_xpath\u001b[39m(xpath):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:740\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    737\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    738\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:346\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    344\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"app\"]/div/div/div[2]/div[2]/div[5]/div[2]/div[1]/textarea\"}\n  (Session info: chrome=114.0.5735.134); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x0031A813+48355]\n\t(No symbol) [0x002AC4B1]\n\t(No symbol) [0x001B5358]\n\t(No symbol) [0x001E09A5]\n\t(No symbol) [0x001E0B3B]\n\t(No symbol) [0x0020E232]\n\t(No symbol) [0x001FA784]\n\t(No symbol) [0x0020C922]\n\t(No symbol) [0x001FA536]\n\t(No symbol) [0x001D82DC]\n\t(No symbol) [0x001D93DD]\n\tGetHandleVerifier [0x0057AABD+2539405]\n\tGetHandleVerifier [0x005BA78F+2800735]\n\tGetHandleVerifier [0x005B456C+2775612]\n\tGetHandleVerifier [0x003A51E0+616112]\n\t(No symbol) [0x002B5F8C]\n\t(No symbol) [0x002B2328]\n\t(No symbol) [0x002B240B]\n\t(No symbol) [0x002A4FF7]\n\tBaseThreadInitThunk [0x764C7D59+25]\n\tRtlInitializeExceptionChain [0x778DB74B+107]\n\tRtlClearBits [0x778DB6CF+191]\n"
     ]
    }
   ],
   "source": [
    "def css_finds(css_selector):\n",
    "    return browser.find_elements(By.CSS_SELECTOR, css_selector)\n",
    "\n",
    "def css_find(css_selector):\n",
    "    return browser.find_element(By.CSS_SELECTOR, css_selector)\n",
    "\n",
    "def find(wait, css_selector):\n",
    "    return wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))\n",
    "\n",
    "def finds_xpath(xpath):\n",
    "    return browser.find_elements(By.XPATH, xpath)\n",
    "\n",
    "def find_xpath(xpath):\n",
    "    return browser.find_element(By.XPATH, xpath)\n",
    "\n",
    "def find_id(id_x):\n",
    "    return browser.find_element(By.ID, id_x)\n",
    "\n",
    "# Options Setting\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('no-sandox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('incognito')\n",
    "# options.add_argument('headless')\n",
    "# Header Setting\n",
    "service = Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "\n",
    "# Settings\n",
    "NAVER_ID = \"sjk5838\"\n",
    "NAVER_PW = \"rlatjdwls00@K\"\n",
    "\n",
    "CAFENAME = \"1motion1\"\n",
    "BORADTITLE = \"전체글보기\"\n",
    "\n",
    "keyword = \"3D\"\n",
    "COMMENTS = \"테스트 댓글 입니다.\"\n",
    "\n",
    "# def 1\n",
    "# Crawling Start\n",
    "browser.get(\"https://nid.naver.com/nidlogin.login\")\n",
    "browser.implicitly_wait(2)\n",
    "\n",
    "input_id = find_id('id')\n",
    "input_pw = find_id('pw')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "pyperclip.copy(NAVER_ID) \n",
    "input_id.send_keys(Keys.CONTROL, \"v\")\n",
    "\n",
    "pyperclip.copy(NAVER_PW) \n",
    "input_pw.send_keys(Keys.CONTROL, \"v\")\n",
    "input_pw.send_keys(\"\\n\")\n",
    "\n",
    "# Not needed when it's headless\n",
    "# no_save_btn = find_id('new.dontsave')\n",
    "# no_save_btn.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# def 2\n",
    "browser.get(f\"https://cafe.naver.com/{CAFENAME}\")\n",
    "time.sleep(2)\n",
    "\n",
    "boardName = browser.find_element(By.LINK_TEXT, f'{BORADTITLE}')\n",
    "\n",
    "boardName.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "browser.switch_to.frame(\"cafe_main\")\n",
    "\n",
    "browser.find_element(By.XPATH, '//*[@id=\"listSizeSelectDiv\"]/a').click()\n",
    "browser.find_element(By.XPATH, '//*[@id=\"listSizeSelectDiv\"]/ul/li[7]/a').click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "soup = BS(browser.page_source, \"html.parser\")\n",
    "soup = soup.find_all(class_='article-board m-tcol-c')[1]\n",
    "\n",
    "datas = soup.find_all(class_='td_article')\n",
    "dates = soup.find_all(class_='td_date')\n",
    "\n",
    "a_hrefs = soup.find_all(\"a\")\n",
    "\n",
    "# def 3\n",
    "post_hrefs = []\n",
    "for href in a_hrefs:\n",
    "    if keyword in href.text:\n",
    "        post_hrefs.append(href[\"href\"])\n",
    "\n",
    "final_hrefs = []\n",
    "\n",
    "for href in post_hrefs:\n",
    "    parsed_url = urlparse(href)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    article_id = query_params['articleid'][0]\n",
    "    club_id = query_params['clubid'][0]\n",
    "    new_url = f\"https://cafe.naver.com/{CAFENAME}?iframe_url_utf8=%2FArticleRead.nhn%253Fclubid%3D{club_id}%2526page%3D1%2526boardtype%3DL%2526articleid%3D{article_id}%2526referrerAllArticles%3Dtrue\"\n",
    "    \n",
    "    final_hrefs.append(new_url)\n",
    "\n",
    "# def 4\n",
    "for r_href in final_hrefs:\n",
    "    browser.get(r_href)\n",
    "    browser.switch_to.frame(\"cafe_main\")\n",
    "    \n",
    "    text_area = find_xpath('//*[@id=\"app\"]/div/div/div[2]/div[2]/div[5]/div[2]/div[1]/textarea')\n",
    "    text_area.click()\n",
    "\n",
    "pyperclip.copy(COMMENTS) \n",
    "text_area.send_keys(Keys.CONTROL, \"v\")\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "browser.find_element(By.XPATH, '/html/body/div/div/div/div[2]/div[2]/div[5]/div[2]/div[2]/div[2]/a').click()\n",
    "\n",
    "browser.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "67e4d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "final_hrefs = []\n",
    "\n",
    "for href in post_hrefs:\n",
    "    parsed_url = urlparse(href)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    article_id = query_params['articleid'][0]\n",
    "    club_id = query_params['clubid'][0]\n",
    "    new_url = f\"https://cafe.naver.com/1motion1?iframe_url_utf8=%2FArticleRead.nhn%253Fclubid%3D{club_id}%2526page%3D1%2526boardtype%3DL%2526articleid%3D{article_id}%2526referrerAllArticles%3Dtrue\"\n",
    "    \n",
    "    final_hrefs.append(new_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28f2f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "for po in post_hrefs:\n",
    "    da_1 = po.split(\"&\")\n",
    "    print(da_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = browser.find_elements(By.CSS_SELECTOR, '.comment')\n",
    "for comment in comments:\n",
    "    nickname = comment.find_element_by_css_selector('.user_name').text\n",
    "    \n",
    "    if nickname == my_nickname:\n",
    "        # 다른 URL로 넘어가는 로직 작성\n",
    "        continue\n",
    "    \n",
    "    comment_textarea = comment.find_element_by_css_selector('.comment_input textarea')\n",
    "    comment_textarea.send_keys(comment_content)\n",
    "    comment_button = comment.find_element_by_css_selector('.comment_input .comment_submit')\n",
    "    comment_button.click()\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0a3d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "crawling_page = int(math.ceil(100 / 50)+1)\n",
    "print(crawling_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "da3d2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_finds(css_selector):\n",
    "    return browser.find_elements(By.CSS_SELECTOR, css_selector)\n",
    "\n",
    "def css_find(css_selector):\n",
    "    return browser.find_element(By.CSS_SELECTOR, css_selector)\n",
    "\n",
    "def find(wait, css_selector):\n",
    "    return wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))\n",
    "\n",
    "def finds_xpath(xpath):\n",
    "    return browser.find_elements(By.XPATH, xpath)\n",
    "\n",
    "def find_xpath(xpath):\n",
    "    return browser.find_element(By.XPATH, xpath)\n",
    "\n",
    "def find_id(id_x):\n",
    "    return browser.find_element(By.ID, id_x)\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('no-sandox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('incognito')\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=service, options=options)    \n",
    "\n",
    "# Settings\n",
    "NAVER_ID = \"sjk5838\"\n",
    "NAVER_PW = \"rlatjdwls00@K\"\n",
    "\n",
    "CAFENAME = \"1motion1\"\n",
    "BORADTITLE = \"전체글보기\"\n",
    "NICKNAME = \"최고의일베충소정\"\n",
    "\n",
    "keyword = \"3D\"\n",
    "COMMENTS = \"\"\"\n",
    "Test \n",
    "TestTest \n",
    "TestTest \n",
    "\n",
    "test\n",
    "\"\"\"\n",
    "\n",
    "# def 1\n",
    "# Crawling Start\n",
    "\n",
    "browser.get(\"https://nid.naver.com/nidlogin.login\")\n",
    "browser.implicitly_wait(2)\n",
    "\n",
    "input_id = find_id('id')\n",
    "input_pw = find_id('pw')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "pyperclip.copy(NAVER_ID)\n",
    "input_id.send_keys(Keys.CONTROL, \"v\")\n",
    "\n",
    "pyperclip.copy(NAVER_PW) \n",
    "input_pw.send_keys(Keys.CONTROL, \"v\")\n",
    "input_pw.send_keys(\"\\n\")\n",
    "\n",
    "# Not needed when it's headless\n",
    "# no_save_btn = find_id('new.dontsave')\n",
    "# no_save_btn.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# def 2\n",
    "browser.get(f\"https://cafe.naver.com/{CAFENAME}\")\n",
    "time.sleep(2)\n",
    "\n",
    "boardName = browser.find_element(By.LINK_TEXT, f'{BORADTITLE}')\n",
    "\n",
    "boardName.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "browser.switch_to.frame(\"cafe_main\")\n",
    "\n",
    "browser.find_element(By.XPATH, '//*[@id=\"listSizeSelectDiv\"]/a').click()\n",
    "browser.find_element(By.XPATH, '//*[@id=\"listSizeSelectDiv\"]/ul/li[7]/a').click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "soup = BS(browser.page_source, \"html.parser\")\n",
    "soup = soup.find_all(class_='article-board m-tcol-c')[1]\n",
    "\n",
    "datas = soup.find_all(class_='td_article')\n",
    "dates = soup.find_all(class_='td_date')\n",
    "\n",
    "a_hrefs = soup.find_all(\"a\")\n",
    "\n",
    "# def 3\n",
    "post_hrefs = []\n",
    "for href in a_hrefs:\n",
    "    if keyword in href.text:\n",
    "        post_hrefs.append(href[\"href\"])\n",
    "\n",
    "final_hrefs = []\n",
    "\n",
    "for href in post_hrefs:\n",
    "    parsed_url = urlparse(href)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    article_id = query_params['articleid'][0]\n",
    "    club_id = query_params['clubid'][0]\n",
    "    new_url = f\"https://cafe.naver.com/{CAFENAME}?iframe_url_utf8=%2FArticleRead.nhn%253Fclubid%3D{club_id}%2526page%3D1%2526boardtype%3DL%2526articleid%3D{article_id}%2526referrerAllArticles%3Dtrue\"\n",
    "\n",
    "    final_hrefs.append(new_url)\n",
    "\n",
    "# def 4\n",
    "\n",
    "# browser.get(\"https://cafe.naver.com/1motion1?iframe_url_utf8=%2FArticleRead.nhn%253Fclubid%3D28520242%2526page%3D1%2526boardtype%3DL%2526articleid%3D553%2526referrerAllArticles%3Dtrue\")\n",
    "\n",
    "# time.sleep(1)\n",
    "\n",
    "# browser.switch_to.frame(\"cafe_main\")\n",
    "\n",
    "# time.sleep(1)\n",
    "# comments_not_allowed = browser.find_element(By.CSS_SELECTOR, 'button_comment not_allowed')\n",
    "# print(comments_not_allowed)\n",
    "\n",
    "# nickname = NICKNAME\n",
    "# nicksname = browser.find_element(By.CLASS_NAME, 'comment_inbox_name').text\n",
    "\n",
    "# cmtNicks = browser.find_elements(By.CLASS_NAME, 'comment_nickname')\n",
    "# text_area = browser.find_element(By.CLASS_NAME, 'comment_inbox_text')\n",
    "# text_area.click()\n",
    "\n",
    "# pyperclip.copy(COMMENTS)\n",
    "# text_area.send_keys(Keys.CONTROL, \"v\")\n",
    "\n",
    "# time.sleep(2)\n",
    "\n",
    "# register_btn = browser.find_element(By.CLASS_NAME, 'btn_register')\n",
    "# register_btn.click()\n",
    "\n",
    "\n",
    "cmtnicks = []\n",
    "\n",
    "for p_href in final_hrefs:\n",
    "    browser.get(p_href)\n",
    "    time.sleep(1)\n",
    "    browser.switch_to.frame(\"cafe_main\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "#         nicksname = browser.find_element(By.CLASS_NAME, 'comment_inbox_name').text\n",
    "        nickname = NICKNAME\n",
    "        cmtNicks = browser.find_elements(By.CLASS_NAME, 'comment_nickname')\n",
    "\n",
    "        if cmtNicks:\n",
    "            for cmtNick in cmtNicks:\n",
    "                cmtnick = cmtNick.text\n",
    "                cmtnicks.append(cmtnick)\n",
    "\n",
    "            if nickname in cmtnicks:\n",
    "                # 내 닉네임으로 댓글이 있는 경우, 다음 페이지로 넘어감\n",
    "                continue\n",
    "            else:\n",
    "                # 내 닉네임으로 댓글이 없는 경우, 댓글 작성\n",
    "                time.sleep(1)\n",
    "                text_area = browser.find_element(By.CLASS_NAME, 'comment_inbox_text')\n",
    "                text_area.click()\n",
    "\n",
    "                pyperclip.copy(COMMENTS) \n",
    "                text_area.send_keys(Keys.CONTROL, \"v\")\n",
    "                register_btn = browser.find_element(By.CLASS_NAME, 'btn_register')\n",
    "                register_btn.click()\n",
    "        else:\n",
    "            # 댓글 작성\n",
    "            time.sleep(1)\n",
    "            text_area = browser.find_element(By.CLASS_NAME, 'comment_inbox_text')\n",
    "            text_area.click()\n",
    "\n",
    "            pyperclip.copy(COMMENTS) \n",
    "            text_area.send_keys(Keys.CONTROL, \"v\")\n",
    "            register_btn = browser.find_element(By.CLASS_NAME, 'btn_register')\n",
    "            register_btn.click()\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    cmtnicks.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fdb814f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "301627c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://cafe.naver.com/1motion1?iframe_url_utf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://cafe.naver.com/1motion1?iframe_url_utf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://cafe.naver.com/1motion1?iframe_url_utf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  https://cafe.naver.com/1motion1?iframe_url_utf...\n",
       "1  https://cafe.naver.com/1motion1?iframe_url_utf...\n",
       "2  https://cafe.naver.com/1motion1?iframe_url_utf..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51f9fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtnicks = []\n",
    "\n",
    "for p_href in final_hrefs:\n",
    "    browser.get(p_href)\n",
    "    time.sleep(1)\n",
    "    browser.switch_to.frame(\"cafe_main\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    nickname = NICKNAME\n",
    "\n",
    "    cmtNicks = browser.find_elements(By.CLASS_NAME, 'comment_nickname')\n",
    "    \n",
    "    if cmtNicks:\n",
    "        for cmtNick in cmtNicks:\n",
    "            cmtnick = cmtNick.text\n",
    "            cmtnicks.append(cmtnick)\n",
    "\n",
    "        if nickname in cmtnicks:\n",
    "            # 내 닉네임으로 댓글이 있는 경우, 다음 페이지로 넘어감\n",
    "            continue\n",
    "        else:\n",
    "            # 내 닉네임으로 댓글이 없는 경우, 댓글 작성\n",
    "            time.sleep(1)\n",
    "            text_area = browser.find_element(By.CLASS_NAME, 'comment_inbox_text')\n",
    "            text_area.click()\n",
    "\n",
    "            pyperclip.copy(COMMENTS) \n",
    "            text_area.send_keys(Keys.CONTROL, \"v\")\n",
    "            browser.find_element(By.XPATH, '/html/body/div/div/div/div[2]/div[2]/div[5]/div[2]/div[2]/div[2]/a').click()\n",
    "    else:\n",
    "        # 댓글 작성\n",
    "        time.sleep(1)\n",
    "        text_area = browser.find_element(By.CLASS_NAME, 'comment_inbox_text')\n",
    "        text_area.click()\n",
    "\n",
    "        pyperclip.copy(COMMENTS) \n",
    "        text_area.send_keys(Keys.CONTROL, \"v\")\n",
    "        browser.find_element(By.XPATH, '/html/body/div/div/div/div[2]/div[2]/div[5]/div[2]/div[2]/div[2]/a').click()\n",
    "\n",
    "    cmtnicks.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0241bb7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (236959528.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[61], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    def crawling_start(NAVER_ID, NAVER_PW, CAFENAME, keyword = \"전체글보기\", COMMENTS):\u001b[0m\n\u001b[1;37m                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def crawling_start(NAVER_ID, NAVER_PW, CAFENAME, keyword = \"전체글보기\", COMMENTS):\n",
    "    def selenuim_setting():\n",
    "        # Options Setting\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('no-sandox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        options.add_argument('--start-maximized')\n",
    "        options.add_argument('incognito')\n",
    "        # options.add_argument('headless')\n",
    "        # Header Setting\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        browser = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "        return browser\n",
    "\n",
    "    def naverMarco(browser):\n",
    "        def css_finds(css_selector):\n",
    "            return browser.find_elements(By.CSS_SELECTOR, css_selector)\n",
    "\n",
    "        def css_find(css_selector):\n",
    "            return browser.find_element(By.CSS_SELECTOR, css_selector)\n",
    "\n",
    "        def find(wait, css_selector):\n",
    "            return wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))\n",
    "\n",
    "        def finds_xpath(xpath):\n",
    "            return browser.find_elements(By.XPATH, xpath)\n",
    "\n",
    "        def find_xpath(xpath):\n",
    "            return browser.find_element(By.XPATH, xpath)\n",
    "\n",
    "        def find_id(id_x):\n",
    "            return browser.find_element(By.ID, id_x)\n",
    "\n",
    "        \n",
    "        browser.get(\"https://nid.naver.com/nidlogin.login\")\n",
    "        browser.implicitly_wait(2)\n",
    "\n",
    "        input_id = find_id('id')\n",
    "        input_pw = find_id('pw')\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        pyperclip.copy(NAVER_ID) \n",
    "        input_id.send_keys(Keys.CONTROL, \"v\")\n",
    "\n",
    "        pyperclip.copy(NAVER_PW) \n",
    "        input_pw.send_keys(Keys.CONTROL, \"v\")\n",
    "        input_pw.send_keys(\"\\n\")\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "        browser.get(f\"https://cafe.naver.com/{CAFENAME}\")\n",
    "        \n",
    "        time.sleep(2)\n",
    "\n",
    "        boardName = browser.find_element(By.LINK_TEXT, f'{BORADTITLE}')\n",
    "        boardName.click()\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        browser.switch_to.frame(\"cafe_main\")\n",
    "\n",
    "        browser.find_element(By.XPATH, '//*[@id=\"listSizeSelectDiv\"]/a').click()\n",
    "        browser.find_element(By.XPATH, '//*[@id=\"listSizeSelectDiv\"]/ul/li[7]/a').click()\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        soup = BS(browser.page_source, \"html.parser\")\n",
    "        soup = soup.find_all(class_='article-board m-tcol-c')[1]\n",
    "\n",
    "        datas = soup.find_all(class_='td_article')\n",
    "        dates = soup.find_all(class_='td_date')\n",
    "\n",
    "        a_hrefs = soup.find_all(\"a\")\n",
    "        \n",
    "        \n",
    "        post_hrefs = []\n",
    "        \n",
    "        for href in a_hrefs:\n",
    "            if keyword in href.text:\n",
    "                post_hrefs.append(href[\"href\"])\n",
    "\n",
    "                \n",
    "        final_hrefs = []\n",
    "\n",
    "        for href in post_hrefs:\n",
    "            parsed_url = urlparse(href)\n",
    "            query_params = parse_qs(parsed_url.query)\n",
    "            article_id = query_params['articleid'][0]\n",
    "            club_id = query_params['clubid'][0]\n",
    "            new_url = f\"https://cafe.naver.com/{CAFENAME}?iframe_url_utf8=%2FArticleRead.nhn%253Fclubid%3D{club_id}%2526page%3D1%2526boardtype%3DL%2526articleid%3D{article_id}%2526referrerAllArticles%3Dtrue\"\n",
    "\n",
    "            final_hrefs.append(new_url)\n",
    "\n",
    "            \n",
    "        cmtnicks = []\n",
    "\n",
    "        for p_href in final_hrefs:\n",
    "            browser.get(p_href)\n",
    "            time.sleep(1)\n",
    "            browser.switch_to.frame(\"cafe_main\")\n",
    "            time.sleep(1)\n",
    "\n",
    "            try:\n",
    "                nicksname = browser.find_element(By.CLASS_NAME, 'comment_inbox_name').text\n",
    "                cmtNicks = browser.find_elements(By.CLASS_NAME, 'comment_nickname')\n",
    "\n",
    "                if cmtNicks:\n",
    "                    for cmtNick in cmtNicks:\n",
    "                        cmtnick = cmtNick.text\n",
    "                        cmtnicks.append(cmtnick)\n",
    "\n",
    "                    if nickname in cmtnicks:\n",
    "                        # 내 닉네임으로 댓글이 있는 경우, 다음 페이지로 넘어감\n",
    "                        continue\n",
    "                    else:\n",
    "                        # 내 닉네임으로 댓글이 없는 경우, 댓글 작성\n",
    "                        time.sleep(1)\n",
    "                        text_area = browser.find_element(By.CLASS_NAME, 'comment_inbox_text')\n",
    "                        text_area.click()\n",
    "\n",
    "                        pyperclip.copy(COMMENTS) \n",
    "                        text_area.send_keys(Keys.CONTROL, \"v\")\n",
    "                        register_btn = browser.find_element(By.CLASS_NAME, 'btn_register')\n",
    "                        register_btn.click()\n",
    "                else:\n",
    "                    # 댓글 작성\n",
    "                    time.sleep(1)\n",
    "                    text_area = browser.find_element(By.CLASS_NAME, 'comment_inbox_text')\n",
    "                    text_area.click()\n",
    "\n",
    "                    pyperclip.copy(COMMENTS) \n",
    "                    text_area.send_keys(Keys.CONTROL, \"v\")\n",
    "                    register_btn = browser.find_element(By.CLASS_NAME, 'btn_register')\n",
    "                    register_btn.click()\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            cmtnicks.clear()\n",
    "            \n",
    "            df = pd.DataFrame(final_hrefs)\n",
    "            \n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f58bd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cmtNicks:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ce49c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cafe.naver.com/1motion1?iframe_url_utf8=%2FArticleRead.nhn%253Fclubid%3D28520242%2526page%3D1%2526boardtype%3DL%2526articleid%3D559%2526referrerAllArticles%3Dtrue\n"
     ]
    }
   ],
   "source": [
    "print(final_hrefs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86789230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37689eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C://Users//user//Downloads//test_travel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2f96ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d14e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd4cc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['연락처'].str.contains(\"\\+82\" , na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "adaafff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21    연락처 정보+82 10-8262-6228휴대폰웹사이트 및 소셜 링크표시할 링크 없음...\n",
       "67    연락처 정보+82 10-9612-2352휴대폰웹사이트 및 소셜 링크표시할 링크 없음...\n",
       "71    연락처 정보+82 10-3654-1504휴대폰sojungland@naver.com이...\n",
       "Name: 연락처, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['연락처']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295fc24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
